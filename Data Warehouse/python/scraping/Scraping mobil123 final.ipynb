{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d660a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "from subprocess import call\n",
    "\n",
    "pdf_url = \"\"\n",
    "pdf_filename = \"\"\n",
    "call([\"curl\", pdf_url, \n",
    "    '-H', 'Connection: keep-alive', \n",
    "    '-H', 'Cache-Control: max-age=0', \n",
    "    '-H', 'Upgrade-Insecure-Requests: 1', \n",
    "    '-H', 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36', \n",
    "    '-H', 'Sec-Fetch-Mode: navigate', \n",
    "    '-H', 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3', \n",
    "    '-H', 'Sec-Fetch-Site: cross-site', \n",
    "    '-H', 'Accept-Encoding: gzip, deflate, br', \n",
    "    '-H', 'Accept-Language: en-US,en;q=0.9,bn;q=0.8', \n",
    "    '-H', 'Cookie: bbb=rd102o00000000000000000000ffff978432aao80', \n",
    "    '--compressed', '--output', pdf_filename])\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c04bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cars_dict and cars_no variable\n",
    "cars_dict = {}\n",
    "cars_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbc5f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n",
      "default power\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looping for page of website\n",
    "for n in range(570,605):\n",
    "    # get url and html.parser of page\n",
    "    url = 'https://www.mobil123.com/mobil-dijual/toyota/indonesia?type=used&page_number='+str(n)+'&page_size=25'\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    \n",
    "    # get tag article with class = listing from url\n",
    "    tables = soup.find_all(\"article\", {'class':'listing'})\n",
    "    \n",
    "    # return cars_no variable to self\n",
    "    cars_no = cars_no\n",
    "    # looping for get feature of car\n",
    "    for table in tables:\n",
    "        display_title = table['data-display-title']\n",
    "        line_text = table['data-default-line-text']\n",
    "        brand = table['data-make']\n",
    "        model = table['data-model']\n",
    "        year = table['data-year']\n",
    "        mileage = table['data-mileage']\n",
    "        variant = table['data-variant']\n",
    "        url = table['data-url']\n",
    "        \n",
    "        # get sub url and html.parser of sub page\n",
    "        sub_url  = table['data-url']\n",
    "        sub_page = requests.get(sub_url)\n",
    "        sub_soup = BeautifulSoup(sub_page.text,'html.parser')\n",
    "        \n",
    "        # get tag section\n",
    "        sub_tables = sub_soup.find('section', class_ = 'c-section c-section--key-details u-margin-ends-lg u-margin-ends-sm@mobile u-order-3@mobile')\n",
    "        sub_table_location = sub_soup.find('section', class_ = 'c-section--content u-border-top u-padding-ends-md')\n",
    "        # get feature warna, engine, transmisi, seats\n",
    "        color = sub_tables.find_all('span', class_ = 'u-text-bold u-block')[3].text\n",
    "        engine = sub_tables.find_all('span', class_ = 'u-text-bold u-block')[4].text\n",
    "        transmisi = sub_tables.find_all('span', class_ = 'u-text-bold u-block')[5].text\n",
    "        seats = sub_tables.find_all('span', class_ = 'u-text-bold u-block')[6].text\n",
    "        province = sub_table_location.find_all('span', class_ = 'c-chip c-chip--sm u-rounded u-margin-right-xxs u-margin-bottom-xxs')[0].text\n",
    "        area = sub_table_location.find_all('span', class_ = 'c-chip c-chip--sm u-rounded u-margin-right-xxs u-margin-bottom-xxs')[1].text\n",
    "\n",
    "        # get tag section, div, span from url\n",
    "        spec_section = sub_soup.find('section', class_ = 'c-section--content u-border-top u-padding-ends-md')\n",
    "        spec_div = spec_section.find('div', class_ = \"o-container\")\n",
    "        spec_div2 = spec_div.find('div', class_ = \"c-card__tabs\")\n",
    "        spesifikasi = spec_div2.find_all('span', class_ = ('u-width-1/2', 'u-text-bold u-width-1/2 u-align-right'))\n",
    "\n",
    "        case_list = {}\n",
    "        # get feature from sub page\n",
    "        for n in range(0,len(spesifikasi),2):\n",
    "            case = {spesifikasi[n].text:spesifikasi[n+1].text}\n",
    "            case_list.update(case)\n",
    "        try:\n",
    "            door = case_list['Pintu']\n",
    "        except KeyError:\n",
    "            print('default door')\n",
    "\n",
    "        try:\n",
    "            fuel_type = case_list['Tipe Bahan Bakar']\n",
    "        except KeyError:\n",
    "            print('default fuel')\n",
    "\n",
    "        try:\n",
    "            power = case_list['Tenaga Puncak (hp)']\n",
    "        except KeyError:\n",
    "            print('default power')\n",
    "        \n",
    "        # fill value to cars_dict\n",
    "        cars_dict[cars_no] = [display_title, line_text, url, brand, model, variant, mileage, transmisi, power, engine, door,\n",
    "                         seats, fuel_type, color, year, province, area]\n",
    "        cars_no = cars_no + 1\n",
    "\n",
    "\n",
    "\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "session.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f18e9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_dict_df = pd.DataFrame.from_dict(cars_dict, orient='index',\n",
    "                                      columns=['display_title', 'line_text', 'url', 'brand', 'model', 'variant', \\\n",
    "                                                'mileage', 'transmisi', 'power', 'engine', 'door', 'seats', 'fuel_type', \\\n",
    "                                                'color', 'year', 'province', 'area'])\n",
    "\n",
    "#cars_dict_df.to_csv('mobil123_toyota_full.csv')\n",
    "\n",
    "cars_dict_df.to_csv('mobil123_toyota_full.csv', mode='a', index=True, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "876db7d3f8682b7e4c5477e5f1e2dc2bd1b19fe05d9aabd59218369070754b39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
